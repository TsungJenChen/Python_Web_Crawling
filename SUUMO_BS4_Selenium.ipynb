{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbasecondacbfd5f3f250844ac8b53f2c190fea7ed",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "import lxml \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the URL of the webpage of every district in Tokyo.\n",
    "Including the 23 special wards(特別区), cities(市), towns(町) , and villages(村).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set up the ChromeDriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(\"C:/Users/Nolan/Desktop/.vscode/chromedriver\")\n",
    "browser.get('https://suumo.jp/chintai/tokyo/city/')\n",
    "browser.maximize_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Get URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = browser.find_elements_by_name('sc') #The list of all checkboxes\n",
    "District_URLs = pd.DataFrame(columns=['ID', 'District', 'URL']) #Create a dataframe to store all the URLs\n",
    "for i in range(0,len(boxes)):\n",
    "    browser.get('https://suumo.jp/chintai/tokyo/city/') \n",
    "    boxes = browser.find_elements_by_name('sc') # Find all the checkboxes\n",
    "    label = browser.find_elements_by_tag_name('label') #The name tag of each checkbox\n",
    "\n",
    "    boxes[i].click() #Click the checkbox\n",
    "    idd = boxes[i].get_attribute('id') #Record the ID of the checkboxes\n",
    "    labelid = label[i].get_attribute('for') #Record the ID of the label\n",
    "\n",
    "    if (labelid == idd): \n",
    "        district = label[i].text\n",
    "        district = district.split('(')[0] #Make sure that each checkbox has a corresponding name tag \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    Search_button = browser.find_element_by_xpath('//*[@id=\"js-searchpanel\"]/div/div/a') #The search button\n",
    "    Search_button.click()\n",
    "    url = browser.current_url #Get the url of current page\n",
    "    District_URLs = District_URLs.append({'ID' : idd, 'District': district, 'URL' : url}, ignore_index=True)\n",
    "    \n",
    "    time.sleep(random.randint(5,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Get all the information of the property"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Take Bunkyoku(文京区) for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bunkyo_url = District_URLs.loc[4,'URL']\n",
    "response = rq.get(Bunkyo_url) \n",
    "html_doc = response.text \n",
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2-1  Get the information on any given page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.部屋の特徴・設備 (Features of the object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detail_url(birubody):\n",
    "    detail = birubody.find(\"td\", class_=\"ui-text--midium ui-text--bold\")\n",
    "    detail_a = detail.a['href']\n",
    "    detail_url = 'http://suumo.jp'+ detail_a\n",
    "    detail_response = rq.get(detail_url)\n",
    "    detail_soup = BeautifulSoup(detail_response.text, \"lxml\")\n",
    "    features = detail_soup.find(\"div\", class_ = \"bgc-wht ol-g\")\n",
    "    if (features is None):\n",
    "        return(\"No longer availiable\")\n",
    "    else:\n",
    "        features_text = features.get_text().strip()\n",
    "        return(features_text)\n",
    "    time.sleep(random.uniform(3,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Basic information (Rent, Size, Age, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(District_url):\n",
    "    d = []\n",
    "    global df\n",
    "    #s = 0\n",
    "    response = rq.get(District_url) \n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    biru_set = soup.find_all(\"div\", \"cassetteitem\")\n",
    "\n",
    "    for i in range(len(biru_set)):\n",
    "        biru_body = biru_set[i].find_all(\"tbody\")\n",
    "        title = biru_set[i].find(\"div\",\"cassetteitem_content-title\") #Name of the building\n",
    "        location = biru_set[i].find(\"li\", \"cassetteitem_detail-col1\") #Location of the building\n",
    "        district = location.text.split(sep = \"区\")[0]\n",
    "        district = district + \"区\" #Split the location and extract \"district\" in the address\n",
    "        age = biru_set[i].find(\"li\", \"cassetteitem_detail-col3\").find_all(\"div\")[0] #Age of the building\n",
    "        totalfloor = biru_set[i].find(\"li\", \"cassetteitem_detail-col3\").find_all(\"div\")[1] #Total floor count of the building\n",
    "        for j in range(len(biru_body)):\n",
    "            floor = biru_body[j].find_all(\"td\")[2]\n",
    "            floortext = floor.text.replace('\t\t\t\t\t\t\t\t\t\t\t', '') #Floor\n",
    "            rent = biru_body[j].find(\"span\", class_ = \"cassetteitem_other-emphasis ui-text--bold\") #Rent\n",
    "            madori = biru_body[j].find(\"span\", class_ = \"cassetteitem_madori\") #Layout\n",
    "            menseki = biru_body[j].find(\"span\", class_ = \"cassetteitem_menseki\") #Area\n",
    "            detail = detail_url(biru_body[j]) #More detailed information\n",
    "\n",
    "            d.append((i+1, title.text, district, location.text, floortext.strip(), totalfloor.text, rent.text, madori.text, menseki.text, age.text, detail))\n",
    "\n",
    "        df = pd.DataFrame(d, columns=['BuildingCount', 'BuildingName', 'District', 'Location', 'Floor', 'TotalFloor','Rent', 'Madori', 'Menseki', 'Age', 'Details'])\n",
  
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2-2 Turn pages automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TurnPage(District_url):\n",
    "    global df_everypage \n",
    "    df_everypage =  pd.DataFrame()\n",
    "    response = rq.get(District_url) \n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    pagesection = soup.find(\"div\", class_ = \"pagination pagination_set-nav\") # Find the page button section\n",
    "    totalpagescount = pagesection.find(\"ol\", \"pagination-parts\").find_all(\"li\")[-1].text # The number on the last page button is the total number of the pages that we have to page through\n",
    "    \n",
    "    for p in range(1,int(totalpagescount)+1):#\n",
    "        urls = Bunkyo_url +'&et=9999999&page1&page='+str(p)\n",
    "        getInfo(urls)\n",
    "        df[\"From Page #\"] = p\n",
    "        df_everypage = df_everypage.append(df)\n",
    "        time.sleep(random.uniform(5,10))\n",
    "    return(df_everypage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Repeat step 2 on every district in Tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oneclick(URL_list):\n",
    "    global Tokyo_Dataset\n",
    "    Tokyo_Dataset = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(URL_list)):\n",
    "        D = TurnPage(URL_list.loc[i,'URL'])\n",
    "        Tokyo_Dataset = Tokyo_Dataset.append(D)\n",
    "        \n",
    "    return(Tokyo_DataSet)"
   ]
  }
 ]
}
